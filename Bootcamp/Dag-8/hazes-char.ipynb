{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 22:45:49.270619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-16 22:45:49.270647: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 22:45:51.137858: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-16 22:45:51.138980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-16 22:45:51.138997: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-16 22:45:51.139020: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (archlinux): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, GRU\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a corpus of 41701 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"hazes.txt\") as corpus_file:\n",
    "    corpus = corpus_file.read()\n",
    "    corpus = corpus.lower()\n",
    "print(\"Loaded a corpus of {0} characters\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '\"', \"'\", '(', ')', ',', '.', '1', '2', ':', ';', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Our corpus contains 39 unique characters.\n",
      "{'\\n': 0, ' ': 1, '\"': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '.': 7, '1': 8, '2': 9, ':': 10, ';': 11, '?': 12, '`': 13, 'a': 14, 'b': 15, 'c': 16, 'd': 17, 'e': 18, 'f': 19, 'g': 20, 'h': 21, 'i': 22, 'j': 23, 'k': 24, 'l': 25, 'm': 26, 'n': 27, 'o': 28, 'p': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38}\n"
     ]
    }
   ],
   "source": [
    "# Get a unique identifier for each char in the corpus, then make some dicts to ease encoding and decoding\n",
    "chars = sorted(list(set(corpus)))\n",
    "num_chars = len(chars)\n",
    "encoding = {c: i for i, c in enumerate(chars)}\n",
    "decoding = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "print(chars)\n",
    "print(\"Our corpus contains {0} unique characters.\".format(num_chars))\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# it slices, it dices, it makes julienned datasets!\n",
    "# chop up our data into X and y, slice into roughly (num_chars / skip) overlapping 'sentences'\n",
    "# of length sentence_length, and encode the chars\n",
    "sentence_length = 20\n",
    "skip = 1\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range (0, len(corpus) - sentence_length, skip):\n",
    "    sentence = corpus[i:i + sentence_length]\n",
    "    next_char = corpus[i + sentence_length]\n",
    "    X_data.append([encoding[char] for char in sentence])\n",
    "    y_data.append(encoding[next_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41681\n"
     ]
    }
   ],
   "source": [
    "print(len(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 27, 1, 38, 28, 28, 27, 1, 35, 14, 31, 1, 20, 22, 31, 32, 18, 30, 18, 27],\n",
       " 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[1], y_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([27, 1, 38, 28, 28, 27, 1, 35, 14, 31, 1, 20, 22, 31, 32, 18, 30, 18, 27, 1],\n",
       " 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[2], y_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced our corpus into 41681 sentences of length 20\n"
     ]
    }
   ],
   "source": [
    "num_sentences = len(X_data)\n",
    "print(\"Sliced our corpus into {0} sentences of length {1}\".format(num_sentences, sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing X and y...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98689/2224887287.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((num_sentences, sentence_length, num_chars), dtype=np.bool)\n",
      "/tmp/ipykernel_98689/2224887287.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((num_sentences, num_chars), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorizing X and y...\")\n",
    "X = np.zeros((num_sentences, sentence_length, num_chars), dtype=np.bool)\n",
    "y = np.zeros((num_sentences, num_chars), dtype=np.bool)\n",
    "for i, sentence in enumerate(X_data):\n",
    "    for t, encoded_char in enumerate(sentence):\n",
    "        X[i, t, encoded_char] = 1\n",
    "    y[i, y_data[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check y. Dimension: (41681, 39) # Sentences: 41681 Characters in corpus: 39\n",
      "Sanity check X. Dimension: (41681, 20, 39) Sentence length: 20\n"
     ]
    }
   ],
   "source": [
    "# Double check our vectorized data before we sink hours into fitting a model\n",
    "print(\"Sanity check y. Dimension: {0} # Sentences: {1} Characters in corpus: {2}\".format(y.shape, num_sentences, len(chars)))\n",
    "print(\"Sanity check X. Dimension: {0} Sentence length: {1}\".format(X.shape, sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's build model 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 20, 128)           86016     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 39)                5031      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 39)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,631\n",
      "Trainable params: 222,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define our model\n",
    "print(\"Let's build model 1\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(sentence_length, num_chars), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(num_chars))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 2.7400\n",
      "Epoch 1: loss improved from inf to 2.73996, saving model to weights-01.hdf5\n",
      "326/326 [==============================] - 35s 98ms/step - loss: 2.7400\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 2.1779\n",
      "Epoch 2: loss improved from 2.73996 to 2.17787, saving model to weights-02.hdf5\n",
      "326/326 [==============================] - 32s 97ms/step - loss: 2.1779\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.9579\n",
      "Epoch 3: loss improved from 2.17787 to 1.95794, saving model to weights-03.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.9579\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.8260\n",
      "Epoch 4: loss improved from 1.95794 to 1.82596, saving model to weights-04.hdf5\n",
      "326/326 [==============================] - 32s 97ms/step - loss: 1.8260\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.7265\n",
      "Epoch 5: loss improved from 1.82596 to 1.72650, saving model to weights-05.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.7265\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.6299\n",
      "Epoch 6: loss improved from 1.72650 to 1.62995, saving model to weights-06.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.6299\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.5468\n",
      "Epoch 7: loss improved from 1.62995 to 1.54675, saving model to weights-07.hdf5\n",
      "326/326 [==============================] - 32s 97ms/step - loss: 1.5468\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.4670\n",
      "Epoch 8: loss improved from 1.54675 to 1.46701, saving model to weights-08.hdf5\n",
      "326/326 [==============================] - 32s 99ms/step - loss: 1.4670\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 9: loss improved from 1.46701 to 1.38621, saving model to weights-09.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.3862\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.3082\n",
      "Epoch 10: loss improved from 1.38621 to 1.30816, saving model to weights-10.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.3082\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.2297\n",
      "Epoch 11: loss improved from 1.30816 to 1.22974, saving model to weights-11.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.2297\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.1550\n",
      "Epoch 12: loss improved from 1.22974 to 1.15498, saving model to weights-12.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 1.1550\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.0774\n",
      "Epoch 13: loss improved from 1.15498 to 1.07743, saving model to weights-13.hdf5\n",
      "326/326 [==============================] - 32s 99ms/step - loss: 1.0774\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 1.0033\n",
      "Epoch 14: loss improved from 1.07743 to 1.00332, saving model to weights-14.hdf5\n",
      "326/326 [==============================] - 32s 99ms/step - loss: 1.0033\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.9305\n",
      "Epoch 15: loss improved from 1.00332 to 0.93050, saving model to weights-15.hdf5\n",
      "326/326 [==============================] - 32s 97ms/step - loss: 0.9305\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.8625\n",
      "Epoch 16: loss improved from 0.93050 to 0.86248, saving model to weights-16.hdf5\n",
      "326/326 [==============================] - 32s 99ms/step - loss: 0.8625\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.7931\n",
      "Epoch 17: loss improved from 0.86248 to 0.79314, saving model to weights-17.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 0.7931\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.7285\n",
      "Epoch 18: loss improved from 0.79314 to 0.72847, saving model to weights-18.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 0.7285\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.6643\n",
      "Epoch 19: loss improved from 0.72847 to 0.66435, saving model to weights-19.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 0.6643\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.6068\n",
      "Epoch 20: loss improved from 0.66435 to 0.60680, saving model to weights-20.hdf5\n",
      "326/326 [==============================] - 32s 98ms/step - loss: 0.6068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f58dcd107f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump our model architecture to a file so we can load it elsewhere\n",
    "# Find out how to load a model? ,\n",
    "# return_sequences=True\n",
    "architecture = model.to_json()\n",
    "with open('model.json', 'w') as model_file:\n",
    "    model_file.write(architecture)\n",
    "\n",
    "# Set up checkpoints, and save trained model\n",
    "file_path=\"weights-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor=\"loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# Find out how to load the trained checkpoint?\n",
    "# Lets go, action time!\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
