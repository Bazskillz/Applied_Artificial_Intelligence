{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024636b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 19:38:39.504997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-17 19:38:39.505037: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from random import randint\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4605c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 19:38:41.098581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-17 19:38:41.098613: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-17 19:38:41.098636: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (archlinux): /proc/driver/nvidia/version does not exist\n",
      "2022-02-17 19:38:41.098843: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 20, 128)           86016     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 39)                5031      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 39)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,631\n",
      "Trainable params: 222,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Build our network from loaded architecture and weights\n",
    "with open('model.json') as model_file:\n",
    "    architecture = model_file.read()\n",
    "\n",
    "model = model_from_json(architecture)\n",
    "model.load_weights('weights-05.hdf5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "132b19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a corpus of 41701 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"hazes.txt\") as corpus_file:\n",
    "    corpus = corpus_file.read()\n",
    "    corpus = corpus.lower()\n",
    "print(\"Loaded a corpus of {0} characters\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfa17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(corpus)))\n",
    "num_chars = len(chars)\n",
    "encoding = {c: i for i, c in enumerate(chars)}\n",
    "decoding = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "corpus_length = len(corpus)\n",
    "chars = sorted(list(set(corpus)))\n",
    "sentence_length = 20\n",
    "num_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8645a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  if temperature <= 0:\n",
    "    return np.argmax(preds)\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds) / temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)\n",
    "\n",
    "\n",
    "def generate(seed_pattern):\n",
    "        X = np.zeros((1, sentence_length, num_chars), dtype=np.bool)\n",
    "        #print(X.shape)\n",
    "        for i, character in enumerate(seed_pattern):\n",
    "            X[0, i, encoding[character]] = 1\n",
    "        \n",
    "        generated_text = \"\"\n",
    "        for i in range(500):\n",
    "            # even de temperatuur toevoegen.\n",
    "            prediction = sample(model.predict(X, verbose=0)[0],0.3)\n",
    "            generated_text += decoding[prediction]\n",
    "\n",
    "            activations = np.zeros((1, 1, num_chars), dtype=np.bool)\n",
    "            activations[0, 0, prediction] = 1\n",
    "            X = np.concatenate((X[:, 1:, :], activations), axis=1)\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "def make_seed(seed_phrase=\"\"):\n",
    "        if seed_phrase:\n",
    "            phrase_length = len(seed_phrase)\n",
    "            pattern = \"\"\n",
    "            for i in range (0, sentence_length):\n",
    "                pattern += seed_phrase[i % phrase_length]\n",
    "        else:\n",
    "            seed = randint(0, corpus_length - sentence_length)\n",
    "            pattern = corpus[seed:seed + sentence_length]\n",
    "\n",
    "        return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik denk daarbij stil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112678/2502783996.py:13: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((1, sentence_length, num_chars), dtype=np.bool)\n",
      "/tmp/ipykernel_112678/2502783996.py:24: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  activations = np.zeros((1, 1, num_chars), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de ik de daar mij niet noe taar je heben\n",
      "\n",
      "ik heb ik de het niet verlaan\n",
      "\n",
      "ik heb is het nu niet daar de maar je weer ik de noog met je weer ik zijn\n",
      "\n",
      "ik hee in die nooit\n",
      "ik de krand niet me niet me nooit me kenden\n",
      "\n",
      "ik heb ik de blijf el voor jou laat je nu niet te dat de dan me kenderen dan heer\n",
      "geen dan ik de geen straan\n",
      "\n",
      "het ik de dan met de blijd\n",
      "tor dat ik de krand\n",
      "\n",
      "ik je het niet mijn niet noriet me meer\n",
      "\n",
      "dat ik dat ik de houd ik de dan jou niet me niet noor de laat\n",
      "\n",
      "ik heb ik niet me me niet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = make_seed('ik denk daarbij stilletjes aan taart')\n",
    "print(seed)\n",
    "txt =  generate(seed)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6b6384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}